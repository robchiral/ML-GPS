{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Targets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disease to phecode mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "umls_drugs = pd.read_pickle('./Raw files/drugbank_atc.pkl')\n",
    "\n",
    "drugs = pd.read_parquet(\"./OT_2024.9/molecule.parquet\")\n",
    "drugs['drugbank'] = drugs['crossReferences'].apply(\n",
    "    lambda refs: next((ref[1][0] for ref in refs if ref and ref[0] == 'drugbank'), None) if refs else None\n",
    ")\n",
    "drugs = drugs[['id','blackBoxWarning','name','drugbank','maximumClinicalTrialPhase','isApproved','synonyms','crossReferences','description']]\n",
    "drugs = drugs.merge(umls_drugs, how='left')\n",
    "\n",
    "atc = pd.read_csv('./Raw files/ATC.csv')[['Class ID','Preferred Label']]\n",
    "atc['atc'] = atc['Class ID'].str.split('ATC/').str[-1]\n",
    "atc['name'] = atc['Preferred Label'].str.lower()\n",
    "atc = atc[['name','atc']].drop_duplicates()\n",
    "\n",
    "empty = drugs.loc[drugs['atc'].isna()].drop('atc',axis=1)\n",
    "empty['name'] = empty['name'].str.lower()\n",
    "empty = empty.explode('synonyms')\n",
    "empty['synonyms'] = empty['synonyms'].str.lower()\n",
    "empty = empty.merge(atc, on='name', how='left')\n",
    "empty.loc[empty['atc'].isna(), 'name'] = empty['synonyms']\n",
    "empty = empty.merge(atc, on='name', how='left')\n",
    "empty['atc'] = empty['atc_x'].fillna(empty['atc_y'])\n",
    "empty = empty.drop(['atc_x','atc_y'],axis=1)\n",
    "empty = empty.loc[empty['atc'].notna()]\n",
    "empty = empty[['id','atc']].rename({'atc':'atc_filled'},axis=1).drop_duplicates()\n",
    "\n",
    "drugs = drugs.merge(empty, on='id', how='left')\n",
    "drugs.loc[drugs['atc'].isna(), 'atc'] = drugs['atc_filled']\n",
    "drugs = drugs.drop(['atc_filled','synonyms'],axis=1)\n",
    "\n",
    "drugs['name'] = drugs['name'].str.lower()\n",
    "drugs.to_pickle('./Cleaned files/molecule_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = pd.read_excel('./Phecode/phecodeX_info.xls')\n",
    "pi['phecodeX_code'] = pi['phecode'].str.split('_').str[1]\n",
    "\n",
    "ses = pd.read_csv('./Raw files/hpo-phecodeX_linkswithHPOchildrenExpansion_StrongEvidenceSpecific.tsv', sep='\\t')\n",
    "ses['phecodeX_code'] = ses['phecodeX_code'].astype(str)\n",
    "mp = pd.read_csv('./Raw files/ChildHPO_Precision_X.tsv', sep='\\t')\n",
    "mp['phecodeX_code'] = mp['phecodeX_code'].astype(str)\n",
    "\n",
    "op = pd.concat([ses[['phecodeX_code','phecodeX_label','phecodeX_category']], mp[['phecodeX_code','phecodeX_label','phecodeX_category']]])\n",
    "op = op.drop_duplicates()\n",
    "op = op.merge(pi[['phecode','phecode_string']].rename({'phecode_string':'phecodeX_label'},axis=1), how='left')\n",
    "up = op.loc[op['phecode'].isna()].drop(['phecode'],axis=1)\n",
    "op = op.loc[op['phecode'].notna()]\n",
    "up = up.merge(pi[['phecode','phecodeX_code','phecode_string']], how='inner')\n",
    "up = up.loc[~up['phecodeX_code'].isin(['962.11','324.6','352.2','374.7','375.113','765.3','767.1',\n",
    "                                       '750.12','751.2','757.2','772.1','772.2','978','978.3',\n",
    "                                       '973','975','975.2','705.12','618','582.1','582.2','582.3',\n",
    "                                       '618.1','626.4','374.4','200.11','751.4','168.3','962',\n",
    "                                       '962.1','771','754','752','753.3','977','775','770.4',\n",
    "                                       '770.3','772','771.1','771.3','976','969'])]\n",
    "up = up.drop('phecode_string',axis=1)\n",
    "op = pd.concat([op,up]).drop_duplicates()\n",
    "op = op.merge(pi[['phecode','phecode_string']])\n",
    "\n",
    "ses = ses.merge(op)[['phecode','hpo_code','phecode_string','hpo_label','hpo_child','StrongEvidenceSpecific','StrongEvidenceBroad']]\n",
    "mp = mp.merge(op)[['phecode','hpo_code','phecode_string','hpo_label','hpo_child','StrongEvidenceSpecific','StrongEvidenceBroad']]\n",
    "mp = mp.loc[(mp['StrongEvidenceBroad'] == True) | (mp['StrongEvidenceSpecific'] == True)]\n",
    "map = pd.concat([ses,mp]).drop_duplicates(['phecode','hpo_code']).rename({'hpo_code':'id'},axis=1)\n",
    "map.to_pickle('./Raw files/hpo_phecodex_map.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = pd.read_excel('./Phecode/phecode_counts_v2.xlsx')['phecode'].sort_values().to_list()\n",
    "p1 = pd.read_csv('./Phecode/phecodeX_unrolled_ICD_CM.csv')\n",
    "p2 = pd.read_csv('./Phecode/phecodeX_unrolled_ICD_WHO.csv')\n",
    "comb = pd.concat([p1,p2])\n",
    "comb = comb.loc[comb['phecode'].isin(inc)]\n",
    "comb = comb.rename({'ICD':'code'},axis=1)\n",
    "comb.loc[comb['vocabulary_id'].str.contains('ICD9'), 'icd_type'] = 'ICD9'\n",
    "comb.loc[comb['vocabulary_id'].str.contains('ICD10'), 'icd_type'] = 'ICD10'\n",
    "comb['code'] = comb['code'].astype(str)\n",
    "\n",
    "hp = pd.read_pickle('./Raw files/hpo_phecodex_map.pkl')[['id','phecode']].drop_duplicates()\n",
    "hp['code'] = hp['id'].str.split('_').str[1].astype(str)\n",
    "hp = hp[['phecode','code']]\n",
    "hp['terminology'] = 'HP'\n",
    "hp = hp.loc[hp['phecode'].isin(inc)]\n",
    "\n",
    "disease = pd.read_parquet('./OT_2024.9/diseases.parquet')[['id','dbXRefs','name']]\n",
    "disease = disease.explode('dbXRefs').dropna(subset='dbXRefs')\n",
    "disease['terminology'] = disease['dbXRefs'].str.split(':').str[0]\n",
    "disease['code'] = disease['dbXRefs'].str.split(':').str[1].astype(str)\n",
    "disease = disease[['id','name','terminology','code']]\n",
    "disease.loc[disease['terminology'].str.contains('ICD9'), 'icd_type'] = 'ICD9'\n",
    "disease.loc[disease['terminology'].str.contains('ICD10'), 'icd_type'] = 'ICD10'\n",
    "disease1 = disease.merge(comb, on=['code','icd_type'], how='left')\n",
    "disease2 = disease.merge(hp, on=['code','terminology'], how='left')\n",
    "disease = pd.concat([disease1,disease2]).drop(['icd_type','vocabulary_id'],axis=1)\n",
    "disease.to_pickle('./Cleaned files/diseases_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = pd.read_pickle('./Cleaned files/diseases_cleaned.pkl')\n",
    "map['code'] = map['code'].astype(str)\n",
    "phecode_map = map.loc[map['phecode'].notna()][['id','phecode']]\n",
    "mondo_map = map.loc[map['terminology'] == 'MONDO'][['code','id']]\n",
    "mondo_map = mondo_map.merge(phecode_map)\n",
    "mondo_map['id'] = 'MONDO_' + mondo_map['code'].astype(str)\n",
    "mondo_map = mondo_map[['id','phecode']]\n",
    "hp_map = map.loc[map['terminology'] == 'HP'][['code','id']]\n",
    "hp_map = hp_map.merge(phecode_map)\n",
    "hp_map['id'] = 'HP_' + hp_map['code'].astype(str)\n",
    "hp_map = hp_map[['id','phecode']]\n",
    "orpha_map = map.loc[map['terminology'] == 'Orphanet'][['code','id']]\n",
    "orpha_map = orpha_map.merge(phecode_map)\n",
    "orpha_map['id'] = 'Orphanet_' + orpha_map['code'].astype(str)\n",
    "orpha_map = orpha_map[['id','phecode']]\n",
    "efo_map = map.loc[map['terminology'] == 'EFO'][['code','id']]\n",
    "efo_map = efo_map.merge(phecode_map)\n",
    "efo_map['id'] = 'EFO_' + efo_map['code'].astype(str)\n",
    "efo_map = efo_map[['id','phecode']]\n",
    "inc = pd.read_excel('./Phecode/phecode_counts_v2.xlsx')['phecode'].sort_values().to_list()\n",
    "hp = pd.read_pickle('./Raw files/hpo_phecodex_map.pkl')[['id','phecode']].drop_duplicates()\n",
    "hp = hp.loc[hp['phecode'].isin(inc)]\n",
    "efo_phecode = pd.read_excel('./Raw files/EFO_phecode.xlsx')\\\n",
    "                .merge(pd.read_excel('./Raw files/Phecode_1.2_X_crosswalk.xlsx'), on='phecode v1.2')\\\n",
    "                [['EFO','phecodeX','phecodeX string']]\n",
    "efo_phecode['EFO'] = efo_phecode['EFO'].str.split('efo/').str[1]\n",
    "efo_phecode = efo_phecode[['EFO','phecodeX']].set_axis(['id','phecode'],axis=1).dropna()\n",
    "full_map = pd.concat([hp, phecode_map, mondo_map, hp_map, orpha_map, efo_map, efo_phecode]).drop_duplicates(['id','phecode'])\n",
    "full_map = full_map.rename({'id':'disease'},axis=1)\n",
    "full_map.to_pickle('./Raw files/full_map.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drug indications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "indications = pd.read_parquet('./OT_2024.9/indication.parquet')\n",
    "\n",
    "exploded_indications = indications[['id','approvedIndications']].explode('approvedIndications').dropna()\n",
    "exploded_indications = exploded_indications.rename({'approvedIndications':'disease'},axis=1)\n",
    "exploded_indications['maxPhaseForIndication'] = 4\n",
    "\n",
    "def process_row(row):\n",
    "    id_value = row['id']\n",
    "    result_rows = []\n",
    "    for indication in row['indications']:\n",
    "        disease = indication['disease']\n",
    "        max_phase = indication['maxPhaseForIndication']\n",
    "        result_rows.append({'id': id_value, 'disease': disease, 'maxPhaseForIndication': max_phase})\n",
    "    return result_rows\n",
    "new_rows = []\n",
    "for _, row in indications.iterrows():\n",
    "    new_rows.extend(process_row(row))\n",
    "expanded_df = pd.DataFrame(new_rows)\n",
    "\n",
    "#\n",
    "\n",
    "indications = pd.concat([expanded_df, exploded_indications])\n",
    "indications = indications.rename({'maxPhaseForIndication':'phase'},axis=1)\n",
    "indications = indications.sort_values(['id','disease','phase'], ascending=[True,True,False])\n",
    "indications = indications.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "#\n",
    "\n",
    "full_map = pd.read_pickle('./Raw files/full_map.pkl')\n",
    "indications = indications.merge(full_map)\n",
    "indications.to_pickle('./Cleaned files/indication_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = pd.read_pickle('./Cleaned files/indication_cleaned.pkl')\n",
    "drugs = drugs.merge(pd.read_pickle('./Cleaned files/molecule_cleaned.pkl')[['id','name','atc']], how='left')\n",
    "drugs = drugs.loc[~drugs['atc'].str.startswith('J', na=False)]\n",
    "drugs = drugs[['id','phase','phecode']]\n",
    "\n",
    "moa = pd.read_parquet('./OT_2024.9/mechanismOfAction.parquet')\n",
    "moa['moa'] = 'other'\n",
    "moa.loc[moa['actionType'].isin(['INHIBITOR', 'ANTAGONIST', 'BLOCKER', 'NEGATIVE ALLOSTERIC MODULATOR',\n",
    "                                'ANTISENSE INHIBITOR', 'RELEASING AGENT', 'ALLOSTERIC ANTAGONIST', 'INVERSE AGONIST',\n",
    "                                'NEGATIVE MODULATOR', 'DEGRADER']),'moa'] = 'inhibitor'\n",
    "moa.loc[moa['actionType'].isin(['AGONIST', 'OPENER', 'ACTIVATOR', \n",
    "                                'POSITIVE ALLOSTERIC MODULATOR', 'POSITIVE MODULATOR', \n",
    "                                'PARTIAL AGONIST']),'moa'] = 'activator'\n",
    "moa = moa[['moa','chemblIds','targets']]\n",
    "moa = moa.explode('chemblIds')\n",
    "moa = moa.explode('targets')\n",
    "moa = moa.merge(pd.read_parquet('./OT_2024.9/targets.parquet')[['id','approvedSymbol']].rename({'id':'targets'},axis=1))\n",
    "moa = moa.rename({'chemblIds':'id'},axis=1).drop_duplicates()\n",
    "\n",
    "drugs = moa.merge(drugs,how='left')[['id','phase','phecode','moa','approvedSymbol']]\n",
    "drugs = drugs.rename({'approvedSymbol':'gene'},axis=1)\n",
    "drugs.to_pickle('./Cleaned files/opentargets.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct and indirect association scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_parquet('./OT_2024.9/associationByOverallDirect.parquet').set_axis(['disease','targetId','direct_score','direct_count'],axis=1)\n",
    "ids = pd.read_parquet('./OT_2024.9/associationByOverallIndirect.parquet').set_axis(['disease','targetId','indirect_score','indirect_count'],axis=1)\n",
    "ass = ds.merge(ids, on=['disease','targetId'], how='outer').fillna(0)\n",
    "full_map = pd.read_pickle('./Raw files/full_map.pkl')\n",
    "ass = ass.merge(full_map)\n",
    "ass = ass.merge(pd.read_parquet('./OT_2024.9/targets.parquet')[['id','approvedSymbol']].drop_duplicates().set_axis(['targetId','gene'],axis=1))\n",
    "ass = ass.groupby(['phecode','gene'])[['direct_score','direct_count','indirect_score','indirect_count']].max().reset_index()\n",
    "ass.to_pickle('./Cleaned files/association_scores_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinical variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVA-ClinVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva = pd.read_parquet('./OT_2024.9/evidence_eva.parquet').rename({'targetId':'target','diseaseId':'disease'},axis=1).sort_values('score',ascending=False)\n",
    "full_map = pd.read_pickle('./Raw files/full_map.pkl')\n",
    "eva = eva.merge(full_map).drop_duplicates(['target','variantId','phecode']).explode('clinicalSignificances')\n",
    "eva = eva.loc[eva['clinicalSignificances'].isin(['pathogenic', 'drug response', 'likely pathogenic', 'association', 'likely risk allele', 'protective'])]\n",
    "eva = eva.loc[eva['confidence'] != 'no assertion criteria provided']\n",
    "targets = pd.read_parquet('./OT_2024.9/targets.parquet')[['id','approvedSymbol']].drop_duplicates()\n",
    "eva = eva.merge(targets, left_on='target', right_on='id')\n",
    "eva = eva[['approvedSymbol','variantId','phecode','score']].set_axis(['gene','variant','phecode','score'],axis=1)\n",
    "eva = eva.loc[eva['variant'].str.contains('_',na=False)]\n",
    "eva.to_pickle('./Cleaned files/eva_clinvar.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locus2gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2g = pd.read_parquet('./OT_2024.9/evidence_l2g.parquet').rename({'targetId':'target','diseaseId':'disease'},axis=1).sort_values('score',ascending=False)\n",
    "full_map = pd.read_pickle('./Raw files/full_map.pkl')\n",
    "l2g = l2g.merge(full_map).drop_duplicates(['target','variantId','phecode'])\n",
    "targets = pd.read_parquet('./OT_2024.9/targets.parquet')[['id','approvedSymbol']].drop_duplicates()\n",
    "l2g = l2g.merge(targets, left_on='target', right_on='id').rename({'approvedSymbol':'gene'},axis=1)\n",
    "\n",
    "l2g['effect'] = 0\n",
    "l2g.loc[(l2g['variantEffect'] == 'GoF') & (l2g['directionOnTrait'] == 'protect'), 'effect'] = 1\n",
    "l2g.loc[(l2g['variantEffect'] == 'GoF') & (l2g['directionOnTrait'] == 'risk'), 'effect'] = -1\n",
    "l2g.loc[(l2g['variantEffect'] == 'LoF') & (l2g['directionOnTrait'] == 'protect'), 'effect'] = -1\n",
    "l2g.loc[(l2g['variantEffect'] == 'LoF') & (l2g['directionOnTrait'] == 'risk'), 'effect'] = 1\n",
    "\n",
    "l2g = l2g.sort_values(['phecode','gene','effect','score'], ascending=[True,True,True,False]).drop_duplicates(['phecode','gene','effect'])\n",
    "\n",
    "temp = l2g[['phecode','gene','score']]\n",
    "temp.loc[temp['score'] > 0.5, 'l2g'] = 1\n",
    "temp.rename({'score':'l2g_score'},axis=1).to_pickle('./Cleaned files/l2g.pkl')\n",
    "\n",
    "temp = pd.pivot(l2g,index=['gene','phecode'],columns='effect',values='score').reset_index().rename({-1:'l2g_inh',0:'l2g_neu',1:'l2g_act'},axis=1)\n",
    "temp.fillna(0).to_pickle('./Cleaned files/l2g_dir.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OMIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/y10yd09d6pg7yv_8hdtwsgf80000gn/T/ipykernel_42378/2620481238.py:9: DtypeWarning: Columns (9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  umls = pd.read_csv('./2024AB_MRCONSO.RRF', sep='|', header=None)[[0,11,13]]\n"
     ]
    }
   ],
   "source": [
    "p1 = pd.read_csv('./Phecode/phecodeX_unrolled_ICD_CM.csv')\n",
    "p2 = pd.read_csv('./Phecode/phecodeX_unrolled_ICD_WHO.csv')\n",
    "comb = pd.concat([p1,p2])\n",
    "comb = comb.rename({'ICD':'code'},axis=1)\n",
    "comb.loc[comb['vocabulary_id'].str.contains('ICD9'), 'icd_type'] = 'ICD9'\n",
    "comb.loc[comb['vocabulary_id'].str.contains('ICD10'), 'icd_type'] = 'ICD10'\n",
    "comb = comb[['phecode','code']]\n",
    "\n",
    "umls = pd.read_csv('./Raw files/2024AB_MRCONSO.RRF', sep='|', header=None)[[0,11,13]]\n",
    "\n",
    "umls_icd = umls.loc[umls[11].str.contains('ICD9|ICD10')]\n",
    "umls_icd = umls_icd.merge(comb, left_on=13, right_on='code')[[0,'phecode']].drop_duplicates()\n",
    "\n",
    "umls_omim = umls.loc[umls[11] == 'OMIM']\n",
    "umls_omim = umls_omim.loc[~umls_omim[13].str.contains('MTHU')]\n",
    "umls_omim = umls_omim.loc[~umls_omim[13].str.contains('.', regex=False)]\n",
    "umls_omim[13] = umls_omim[13].astype(int)\n",
    "umls_omim = umls_omim[[0,13]].merge(umls_icd, on=0)\n",
    "umls_omim = umls_omim[[13,'phecode']].set_axis(['code','phecode'],axis=1)\n",
    "\n",
    "map = pd.read_pickle('./Cleaned files/diseases_cleaned.pkl')\n",
    "map = map.loc[map['terminology'].str.contains('OMIM')]\n",
    "map = map.loc[map['phecode'].notna()][['code','phecode']]\n",
    "map['code'] = map['code'].astype(int)\n",
    "map = pd.concat([map,umls_omim]).drop_duplicates()\n",
    "\n",
    "df = pd.read_csv('./Raw files/genemap2.txt', sep='\\t', skiprows=3)[['Approved Gene Symbol','Phenotypes']].dropna()\n",
    "df['Phenotypes'] = df['Phenotypes'].str.split(';')\n",
    "df = df.explode('Phenotypes')\n",
    "df['MIM'] = df['Phenotypes'].str.extract(r',\\s*(\\d+)\\s*\\(')\n",
    "df['MIM'] = pd.to_numeric(df['MIM'], errors='coerce')\n",
    "df = df[['Approved Gene Symbol','MIM']].set_axis(['Gene','MIM'],axis=1).dropna()\n",
    "df['MIM'] = df['MIM'].astype(int)\n",
    "df = df.rename({'MIM':'code'},axis=1)\n",
    "df = df.merge(map)\n",
    "df = df[['Gene','phecode']].drop_duplicates()\n",
    "df.to_pickle('./Cleaned files/omim.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HGMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/y10yd09d6pg7yv_8hdtwsgf80000gn/T/ipykernel_42378/2847249080.py:12: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./Raw files/2023_4_hg38_fullinfo.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "hid = pd.read_csv('./Raw files/HGMD_HPO_Parent_and_Root_2023_4_Mort.csv')\n",
    "hid = hid.assign(parentAndRoot_HPO_codes=hid['parentAndRoot_HPO_codes'].str.split(',')).explode('parentAndRoot_HPO_codes')\n",
    "hid['code'] = hid['parentAndRoot_HPO_codes'].str.replace('HP:','').str.lstrip('0')\n",
    "hid = hid[['acc_num','code']]\n",
    "hid['code'] = hid['code'].astype(str)\n",
    "\n",
    "hp = pd.read_pickle('./Raw files/hpo_phecodex_map.pkl')[['phecode','id']]\n",
    "hp['code'] = hp['id'].str.replace('HP_', '').str.lstrip('0').astype(int).astype(str)\n",
    "hp = hp[['code','phecode']].drop_duplicates()\n",
    "hid = hid.merge(hp).drop_duplicates().rename({'acc_num':'ID'},axis=1)\n",
    "\n",
    "df = pd.read_csv('./Raw files/2023_4_hg38_fullinfo.tsv', sep='\\t')\n",
    "def parse_info(info_string):\n",
    "    info_dict = {}\n",
    "    for item in info_string.split(';'):\n",
    "        if '=' in item:\n",
    "            key, value = item.split('=', 1)\n",
    "            info_dict[key] = value.strip('\"')\n",
    "    return info_dict\n",
    "parsed_info = df['INFO'].apply(parse_info)\n",
    "df_parsed = pd.DataFrame(parsed_info.tolist())\n",
    "\n",
    "df = df.join(df_parsed)[['CHROM','POS','REF','ALT','DNA','ID','CLASS','GENE']]\n",
    "\n",
    "hgmd = df.merge(hid)\n",
    "hgmd.to_pickle('./Cleaned files/hgmd.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoGoFunc predictions\n",
    "\n",
    "dv = pd.read_pickle('./Raw files/logofunc_preds.pkl')\n",
    "lof_list = dv.loc[dv['Predicted_Label'] == 'LOF']['ID'].drop_duplicates().to_list()\n",
    "gof_list = dv.loc[dv['Predicted_Label'] == 'GOF']['ID'].drop_duplicates().to_list()\n",
    "\n",
    "# Without DOE\n",
    "\n",
    "eva = pd.read_pickle('./Cleaned files/eva_clinvar.pkl').drop_duplicates()\n",
    "eva = eva.groupby(['gene','phecode']).count().reset_index().rename({'variant':'EVA_count'},axis=1)\n",
    "eva['EVA'] = 1\n",
    "\n",
    "hgmd = pd.read_pickle('./Cleaned files/hgmd.pkl').drop_duplicates()\n",
    "hgmd = hgmd.groupby(['GENE','phecode'])['DNA'].count().reset_index().rename({'DNA':'HGMD_count','GENE':'gene'},axis=1)\n",
    "hgmd['HGMD'] = 1\n",
    "\n",
    "omim = pd.read_pickle('./Cleaned files/omim.pkl').drop_duplicates().rename({'Gene':'gene'},axis=1)\n",
    "omim['OMIM'] = 1\n",
    "\n",
    "cv = eva.merge(hgmd, on=['gene','phecode'], how='outer').merge(omim, on=['gene','phecode'], how='outer')\n",
    "cv.to_pickle('./Cleaned files/cv.pkl')\n",
    "\n",
    "# With DOE\n",
    "\n",
    "eva = pd.read_pickle('./Cleaned files/eva_clinvar.pkl').drop_duplicates()\n",
    "eva['LOGO'] = eva['variant'].str.replace('_','-')\n",
    "\n",
    "hgmd = pd.read_pickle('./Cleaned files/hgmd.pkl').drop_duplicates()\n",
    "hgmd['LOGO'] = hgmd['CHROM'].astype(str) + '-' + hgmd['POS'].astype(str) + '-' + hgmd['REF'] + '-' + hgmd['ALT']\n",
    "\n",
    "eva.loc[eva['LOGO'].isin(lof_list), 'EVA_act'] = 1\n",
    "eva.loc[eva['LOGO'].isin(gof_list), 'EVA_inh'] = 1\n",
    "eva.loc[(eva['EVA_act'].isna()) & (eva['EVA_inh'].isna()), 'EVA_neu'] = 1\n",
    "eva = eva.drop_duplicates(['gene','phecode','variant'])\n",
    "eva = eva.groupby(['phecode','gene'])[['EVA_act','EVA_inh','EVA_neu']].sum().reset_index()\n",
    "\n",
    "hgmd.loc[hgmd['LOGO'].isin(lof_list), 'HGMD_act'] = 1\n",
    "hgmd.loc[hgmd['LOGO'].isin(gof_list), 'HGMD_inh'] = 1\n",
    "hgmd.loc[(hgmd['HGMD_act'].isna()) & (hgmd['HGMD_inh'].isna()), 'HGMD_neu'] = 1\n",
    "hgmd = hgmd.drop_duplicates(['GENE','phecode','DNA']).rename({'GENE':'gene'},axis=1)\n",
    "hgmd = hgmd.groupby(['phecode','gene'])[['HGMD_act','HGMD_inh','HGMD_neu']].sum().reset_index()\n",
    "\n",
    "cv_dir = eva.merge(hgmd, on=['phecode','gene'], how='outer')\n",
    "cv_dir.to_pickle('./Cleaned files/cv_dir.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIDER data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drug mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = pd.read_pickle('./Raw files/drug_conv.pkl')\n",
    "\n",
    "#\n",
    "\n",
    "ndr = pd.read_excel('./Raw files/ndr_list.xlsx')\n",
    "ndr = ndr.loc[ndr['ORGANISM'] == 'Homo sapiens']\n",
    "ndr['moa'] = 'other'\n",
    "ndr.loc[ndr['MECHANISM_OF_ACTION'].str.contains('inhibitor|antagonist|blocker|negative allo|antisense|releasing|inverse agonist|negative modulator|degrader', na=False), 'moa'] = 'inhibitor'\n",
    "ndr.loc[(~ndr['MECHANISM_OF_ACTION'].str.contains('inverse|antagonist', na=False)) & (ndr['MECHANISM_OF_ACTION'].str.contains('agonist', na=False)), 'moa'] = 'activator'\n",
    "ndr.loc[ndr['MECHANISM_OF_ACTION'].str.contains('opener|activator|positive allo|positive modulator|partial agonist', na=False), 'moa'] = 'activator'\n",
    "\n",
    "hgnc = pd.read_csv('./Raw files/hgnc_genes.txt', sep='\\t')\n",
    "hgnc = hgnc.sort_values(['HGNC ID','Status']).drop_duplicates('HGNC ID')\n",
    "hgnc = hgnc[['HGNC ID','Approved symbol']].rename({'Approved symbol':'Gene'},axis=1)\n",
    "conv = pd.read_csv('./Raw files/ndr_hgnc.tsv', sep='\\t').set_axis(['ACCESSION','HGNC ID'],axis=1)\n",
    "conv = conv.merge(hgnc)[['ACCESSION', 'Gene']]\n",
    "\n",
    "ndr = ndr.merge(conv)\n",
    "ndr = ndr[['PARENT_PREF_NAME','Gene','moa']].set_axis(['Name','Gene','moa'],axis=1)\n",
    "ndr['Name'] = ndr['Name'].str.lower()\n",
    "ndr = ndr.merge(dc[['name','CID']].dropna(), left_on='Name', right_on='name')\n",
    "ndr = ndr[['CID','Gene','moa']].drop_duplicates()\n",
    "ndr['source'] = 'NDR'\n",
    "\n",
    "#\n",
    "\n",
    "ct = pd.read_csv('./Raw files/chembl_35_drug_targets.csv')\n",
    "ct = ct.loc[ct['organism'] == 'Homo sapiens']\n",
    "ct = ct.loc[ct['syn_type'] == 'GENE_SYMBOL']\n",
    "ct['moa'] = 'other'\n",
    "ct.loc[ct['action_type'].isin(['INHIBITOR', 'ANTAGONIST', 'BLOCKER', 'NEGATIVE ALLOSTERIC MODULATOR',\n",
    "                                'ANTISENSE INHIBITOR', 'RELEASING AGENT', 'ALLOSTERIC ANTAGONIST', 'INVERSE AGONIST',\n",
    "                                'NEGATIVE MODULATOR', 'DEGRADER']),'moa'] = 'inhibitor'\n",
    "ct.loc[ct['action_type'].isin(['AGONIST', 'OPENER', 'ACTIVATOR', \n",
    "                                'POSITIVE ALLOSTERIC MODULATOR', 'POSITIVE MODULATOR', \n",
    "                                'PARTIAL AGONIST']),'moa'] = 'activator'\n",
    "ct = ct[['pref_name','chembl_id','component_synonym','moa']].set_axis(['Name','CHEMBL','Gene','moa'],axis=1)\n",
    "ct['Name'] = ct['Name'].str.lower()\n",
    "ct = pd.concat([ct.merge(dc[['CHEMBL','CID']].dropna()),ct.merge(dc[['name','CID']].dropna(), left_on='Name', right_on='name')])\n",
    "ct['Gene'] = ct['Gene'].str.replace('Synonyms=','')\n",
    "ct = ct[['CID','Gene','moa']].drop_duplicates()\n",
    "ct['source'] = 'ChEMBL'\n",
    "\n",
    "dpa = pd.read_csv('./Raw files/drugbank_pharm_active_5.1.13.csv')\n",
    "dpa = dpa.loc[dpa['Species'] == 'Humans']\n",
    "dpa = dpa.merge(hgnc)\n",
    "dpa = dpa.assign(Drugbank=dpa['Drug IDs'].str.split(';')).explode('Drugbank')\n",
    "dpa = dpa[['Drugbank','Gene','UniProt ID','Species']].drop_duplicates()\n",
    "dpa = dpa[['Drugbank','Gene']].merge(dc[['Drugbank','CID']].dropna())[['Drugbank','CID','Gene']].set_axis(['Drugbank','CID','Gene'],axis=1).drop_duplicates()\n",
    "db_moa = pd.read_pickle('./Raw files/drugbank_moa_5.1.13.pkl')\n",
    "dpa = dpa.merge(db_moa[['Drugbank','Action']])\n",
    "dpa['Action'] = dpa['Action'].str.upper()\n",
    "dpa['moa'] = 'other'\n",
    "dpa.loc[dpa['Action'].isin(['INHIBITOR', 'ANTAGONIST', 'BLOCKER', 'NEGATIVE ALLOSTERIC MODULATOR',\n",
    "                                'ANTISENSE INHIBITOR', 'RELEASING AGENT', 'ALLOSTERIC ANTAGONIST', 'INVERSE AGONIST',\n",
    "                                'NEGATIVE MODULATOR', 'DEGRADER']),'moa'] = 'inhibitor'\n",
    "dpa.loc[dpa['Action'].isin(['AGONIST', 'OPENER', 'ACTIVATOR', \n",
    "                                'POSITIVE ALLOSTERIC MODULATOR', 'POSITIVE MODULATOR', \n",
    "                                'PARTIAL AGONIST']),'moa'] = 'activator'\n",
    "dpa = dpa[['CID','Gene','moa']]\n",
    "dpa['source'] = 'DrugBank'\n",
    "\n",
    "moa = pd.read_parquet('./OT_2024.9/mechanismOfAction.parquet')\n",
    "moa['moa'] = 'other'\n",
    "moa.loc[moa['actionType'].isin(['INHIBITOR', 'ANTAGONIST', 'BLOCKER', 'NEGATIVE ALLOSTERIC MODULATOR',\n",
    "                                'ANTISENSE INHIBITOR', 'RELEASING AGENT', 'ALLOSTERIC ANTAGONIST', 'INVERSE AGONIST',\n",
    "                                'NEGATIVE MODULATOR', 'DEGRADER']),'moa'] = 'inhibitor'\n",
    "moa.loc[moa['actionType'].isin(['AGONIST', 'OPENER', 'ACTIVATOR', \n",
    "                                'POSITIVE ALLOSTERIC MODULATOR', 'POSITIVE MODULATOR', \n",
    "                                'PARTIAL AGONIST']),'moa'] = 'activator'\n",
    "moa = moa[['moa','chemblIds','targets']]\n",
    "moa = moa.explode('chemblIds')\n",
    "moa = moa.explode('targets')\n",
    "moa = moa.merge(pd.read_parquet('./OT_2024.9/targets.parquet')[['id','approvedSymbol']].rename({'id':'targets'},axis=1))\n",
    "moa = moa.rename({'chemblIds':'id'},axis=1).drop_duplicates()\n",
    "moa = moa[['id','approvedSymbol','moa']].dropna().drop_duplicates().set_axis(['CHEMBL','Gene','moa'],axis=1)\n",
    "moa = dc.merge(moa, on=['CHEMBL'])[['CID','Gene','moa']]\n",
    "moa['source'] = 'Open Targets'\n",
    "\n",
    "#\n",
    "\n",
    "targets = pd.concat([dpa,moa,ndr,ct]).drop_duplicates(['CID','Gene'])\n",
    "targets.to_pickle('./Raw files/drug_targets.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MedDRA to phecode mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting phecode indications\n",
    "\n",
    "umls = pd.read_csv('./Raw files/2024AB_MRCONSO.RRF', sep='|', header=None)[[0,11,13]]\n",
    "si = pd.read_csv('./Raw files/meddra_all_indications.tsv', sep='\\t', header=None)\n",
    "temp = si.loc[si[1] != si[5]]\n",
    "temp[1] = temp[5].copy()\n",
    "si = pd.concat([si[[0,1]], temp[[0,1]]]).drop_duplicates()\n",
    "\n",
    "#\n",
    "\n",
    "inc = pd.read_excel('./Phecode/phecode_counts_v2.xlsx')['phecode'].sort_values().to_list()\n",
    "p1 = pd.read_csv('./Phecode/phecodeX_unrolled_ICD_CM.csv')\n",
    "p2 = pd.read_csv('./Phecode/phecodeX_unrolled_ICD_WHO.csv')\n",
    "comb = pd.concat([p1,p2])\n",
    "comb = comb.loc[comb['phecode'].isin(inc)]\n",
    "comb = comb.rename({'ICD':'code'},axis=1)\n",
    "comb.loc[comb['vocabulary_id'].str.contains('ICD9'), 'icd_type'] = 'ICD9'\n",
    "comb.loc[comb['vocabulary_id'].str.contains('ICD10'), 'icd_type'] = 'ICD10'\n",
    "comb = comb[['phecode','code']]\n",
    "\n",
    "umls_icd = umls.loc[umls[11].str.contains('ICD9|ICD10')]\n",
    "umls_icd = umls_icd.merge(comb, left_on=13, right_on='code')[[0,'phecode']].drop_duplicates()\n",
    "\n",
    "umls_hpo = umls.loc[umls[11] == 'HPO']\n",
    "umls_hpo[13] = umls_hpo[13].str.replace('HP:','').str.lstrip('0').astype(int)\n",
    "inc = pd.read_excel('./Phecode/phecode_counts_v2.xlsx')['phecode'].sort_values().to_list()\n",
    "hp = pd.read_pickle('./Raw files/hpo_phecodex_map.pkl')[['phecode','id']]\n",
    "hp['code'] = hp['id'].str.replace('HP_', '').str.lstrip('0').astype(int)\n",
    "hp = hp[['code','phecode']]\n",
    "hp = hp.loc[hp['phecode'].isin(inc)]\n",
    "umls_hpo = umls_hpo.merge(hp, left_on=13, right_on='code')[[0,'phecode']].drop_duplicates()\n",
    "\n",
    "umls_map = pd.concat([umls_hpo,umls_icd]).drop_duplicates()\n",
    "\n",
    "#\n",
    "\n",
    "si = si.merge(umls_map, left_on=1, right_on=0)[['0_x','phecode']].set_axis(['CID','phecode'],axis=1)\n",
    "si.to_pickle('./Raw files/drug_phecode.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sider = pd.read_pickle('./Raw files/drug_targets.pkl')\n",
    "sider = sider.merge(pd.read_pickle('./Raw files/drug_phecode.pkl'), how='left').drop_duplicates()\n",
    "sider = sider.drop('source',axis=1).set_axis(['id','gene','moa','phecode'],axis=1)\n",
    "\n",
    "drug_atc = pd.read_csv('./Raw files/drug_atc.tsv', sep='\\t', header=None)\n",
    "drug_atc = drug_atc.loc[drug_atc[1].str.startswith('J')]\n",
    "sider = sider.loc[~sider['id'].isin(drug_atc[0])]\n",
    "\n",
    "sider.to_pickle('./Cleaned files/sider.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encoding (significant or not)\n",
    "\n",
    "apd = pd.read_pickle('./Raw files/apd.pkl')\n",
    "apd = apd.loc[((apd['cat'] == 'genome') & (apd['eqtl_gene'].notna())) | (apd['cat'] != 'genome')]\n",
    "apd = apd.loc[((apd['cat'] == 'exome') & (apd['FUNCTION'].isin(['missense','PTV']))) | (apd['cat'] != 'exome')]\n",
    "\n",
    "apd['gene'] = apd['eqtl_gene'].copy()\n",
    "apd = apd.reset_index(drop=True)\n",
    "apd.loc[apd['cat'] != 'genome', 'gene'] = apd['gene'].fillna(apd['GENE'])\n",
    "apd = apd.drop_duplicates(['phecode','cat','type','gene'])\n",
    "apd = apd[['phecode','cat','type','gene']]\n",
    "apd['value'] = 1\n",
    "apd['type'] = apd['type'].map({'phecode':'p','continuous':'c','binary':'b'})\n",
    "apd['cat'] = apd['cat'].map({'exome':'e','genome':'g','gb':'b'})\n",
    "apd['col'] = apd['type'] + '_' + apd['cat']\n",
    "apd = pd.pivot_table(apd, index=['phecode','gene'], columns='col', values='value').reset_index()\n",
    "apd.to_pickle('./Cleaned files/apd.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous -log10(p-value) encoding\n",
    "\n",
    "apdz = pd.read_pickle('./Raw files/apd_z.pkl')\n",
    "apdz = apdz.loc[((apdz['cat'] == 'genome') & (apdz['eqtl_gene'].notna())) | (apdz['cat'] != 'genome')]\n",
    "apdz = apdz.loc[((apdz['cat'] == 'exome') & (apdz['FUNCTION'].isin(['missense','PTV']))) | (apdz['cat'] != 'exome')]\n",
    "\n",
    "apdz['gene'] = apdz['eqtl_gene'].copy()\n",
    "apdz = apdz.reset_index(drop=True)\n",
    "apdz.loc[apdz['cat'] != 'genome', 'gene'] = apdz['gene'].fillna(apdz['GENE'])\n",
    "apdz = apdz.sort_values('LOG10P', ascending=False).drop_duplicates(['phecode','cat','type','gene'])\n",
    "apdz = apdz[['phecode','cat','type','gene','LOG10P']]\n",
    "apdz['type'] = apdz['type'].map({'phecode':'p','continuous':'c','binary':'b'})\n",
    "apdz['cat'] = apdz['cat'].map({'exome':'e','genome':'g','gb':'b'})\n",
    "apdz['col'] = apdz['type'] + '_' + apdz['cat'] + '_z'\n",
    "apdz = pd.pivot_table(apdz, index=['phecode','gene'], columns='col', values='LOG10P').reset_index()\n",
    "apdz.to_pickle('./Cleaned files/apdz.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous -log10(p-value) encoding with DOE\n",
    "\n",
    "apdz = pd.read_pickle('Raw files/apd_z.pkl')\n",
    "apdz = apdz.loc[apdz['cat'] != 'exome']\n",
    "apdz = apdz.loc[((apdz['cat'] == 'genome') & (apdz['eqtl_gene'].notna())) | (apdz['cat'] != 'genome')]\n",
    "\n",
    "# Here we took the most significant variant for each of activator, inhibitor, or neutral. We used LoGoFunc to generate GOF and LOF predictions.\n",
    "# GOF & beta > 0 = inhibitor\n",
    "# GOF & beta < 0 = activator\n",
    "# LOF & beta > 0 = activator\n",
    "# LOF & beta < 0 = inhibitor\n",
    "\n",
    "apdz_exome = pd.read_pickle('/Raw files/apd_z_exome_DOE.pkl')\n",
    "apdz = pd.concat([apdz,apdz_exome])\n",
    "apdz = apdz[['phecode','cat','type','ID','BETA','LOG10P','GENE','FUNCTION','eqtl_gene','slope','effect']]\n",
    "\n",
    "apdz['gene'] = apdz['eqtl_gene'].copy()\n",
    "apdz = apdz.reset_index(drop=True)\n",
    "apdz.loc[apdz['cat'] != 'genome', 'gene'] = apdz['gene'].fillna(apdz['GENE'])\n",
    "\n",
    "apdz.loc[(apdz['cat'] == 'gb') & (apdz['BETA'] > 0), 'effect'] = 1\n",
    "apdz.loc[(apdz['cat'] == 'gb') & (apdz['BETA'] < 0), 'effect'] = -1\n",
    "\n",
    "apdz.loc[(apdz['slope'] < 0) & (apdz['BETA'] > 0), 'effect'] = 1\n",
    "apdz.loc[(apdz['slope'] > 0) & (apdz['BETA'] < 0), 'effect'] = 1\n",
    "apdz.loc[(apdz['slope'] > 0) & (apdz['BETA'] > 0), 'effect'] = -1\n",
    "apdz.loc[(apdz['slope'] < 0) & (apdz['BETA'] < 0), 'effect'] = -1\n",
    "\n",
    "apdz['effect'] = apdz['effect'].fillna(0)\n",
    "\n",
    "apdz = apdz.sort_values(['LOG10P'], ascending=False).drop_duplicates(['phecode','cat','type','gene','effect'])\n",
    "apdz = apdz[['phecode','cat','type','gene','effect','LOG10P']].dropna()\n",
    "\n",
    "apdz['type'] = apdz['type'].map({'phecode':'p','continuous':'c','binary':'b'})\n",
    "apdz['cat'] = apdz['cat'].map({'exome':'e','genome':'g','gb':'b'})\n",
    "apdz['effect'] = apdz['effect'].map({1:'act',-1:'inh',0:'neu'})\n",
    "apdz['col'] = apdz['type'] + '_' + apdz['cat'] + '_' + apdz['effect']\n",
    "\n",
    "apdz = pd.pivot_table(apdz, index=['phecode','gene'], columns='col', values='LOG10P').reset_index()\n",
    "apdz.fillna(0).to_pickle('./Final/apdz_dir.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
